#@ load("/values.star", "render_on_mgmt_cluster", "render_on_workload_cluster")
#@ load("@ytt:data", "data")
#@ load("/libs/constants.lib.yaml", "post_deploy_job_name", "pinniped_supervisor_namespace", "post_deploy_job_sa_name", "post_deploy_controller_name", "post_deploy_controller_sa_name")

#@ if render_on_mgmt_cluster() or render_on_workload_cluster():
---
apiVersion: v1
kind: Namespace
metadata:
  name: #@ pinniped_supervisor_namespace()
  labels:
    app: pinniped-supervisor
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: #@ post_deploy_job_sa_name()
  namespace: #@ pinniped_supervisor_namespace()
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: tkg-pinniped-post-deploy-cluster-role
rules:
  - apiGroups: [""]
    resources: ["secrets", "configmaps", "services", "pods"]
    verbs: ["get", "list", "delete", "create", "update"]
  - apiGroups: [ "" ]
    resources: [ nodes ]
    verbs: [ "list" ]
  - apiGroups: [ "apps" ]
    resources: [ "deployments" ]
    verbs: [ "get", "list" ]
  - apiGroups: [ "cert-manager.io" ]
    resources: [ "certificates" ]
    verbs: [ "get", "list", "delete","create", "update" ]
  - apiGroups: [ "config.supervisor.pinniped.dev" ]
    resources: [ "federationdomains" ]
    verbs: [ "get", "list", "delete","create", "update" ]
  - apiGroups: [ "authentication.concierge.pinniped.dev" ]
    resources: [ "jwtauthenticators" ]
    verbs: [ "get", "list", "delete","create", "update" ]
  - apiGroups: [ "idp.supervisor.pinniped.dev" ]
    resources: [ "oidcidentityproviders" ]
    verbs: [ "get", "list", "update", "create", "delete" ]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: tkg-pinniped-post-deploy-cluster-role-binding
subjects:
  - kind: ServiceAccount
    name: #@ post_deploy_job_sa_name()
    namespace: #@ pinniped_supervisor_namespace()
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: tkg-pinniped-post-deploy-cluster-role
---
apiVersion: batch/v1
kind: Job
metadata:
  #! TODO: can we append the get_hash() to the name, which will do a sha256.sum(yaml.encode(data.values))
  #! and cause name to be something like pinniped-post-deploy-job-1a2b3c?
  #! This would ensure that every time config changes an entirely NEW JOB is created, and the old job
  #! will be deleted.  This is necessary because Kubernetes does not provide a mechanism for causing a
  #! job to run again.  This means that it is extremely easy for Pinniped Package to get out of sync.
  #! Commonly the FederationDomain, OIDCIdentityProvider and JWTAuthenticators will have incorrect
  #! values.
  #! Sometimes the Job will run again, and sometimes it does not.
  #! Sometimes kapp-controller will execute the YTT templates again causing certain values to revert to
  #! incorrect values, such as a default 0.0.0.0 IP address.  Since post-deploy does not run again when
  #! this happens, good config can be lost.
  #! The necessary fix options are:
  #! - 1. Move all Post-Deploy Job code to a controller.  This would allow for it to watch and actively reconcile.
  #!   - this is likely the most effort/most expensive
  #! - 2. Use the get_hash() function to force unique names to ensure new post-deploy jobs run
  #!   - this may have some side effects
  #!     - is there anything depending on the post-deploy job name?  there should not be, it is not supposed to be public
  #! - 3. Add a CronJob that runs the same container image as the post-deploy Job
  #!     - this could run every 5 minutes and be a resync to ensure that configuration remains correct.
  #!     - this would help the package emulate a proper controller without having to rewrite the job as a controller
  #! Potential snags:
  #! - 1. Is there ever a time when the post-deploy runs and reverts something back to a default value?
  #!      I do recall a "gotcha" of this type somewhere in the flow, but I don't recall if it was post-deploy related.
  name: #@ post_deploy_job_name()
  namespace: #@ pinniped_supervisor_namespace()
spec:
  backoffLimit: 10
  template:
    spec:
      serviceAccount: #@ post_deploy_job_sa_name()
      restartPolicy: Never
      containers:
        - name: pinniped-post-deploy
          image: projects.registry.vmware.com/tce/tanzu_core/addons/tkg-pinniped-post-deploy:v1.3.1
          imagePullPolicy: IfNotPresent
          command: []
#@ end

#@ if render_on_mgmt_cluster():
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: #@ post_deploy_controller_sa_name()
  namespace: #@ pinniped_supervisor_namespace()
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: #@ post_deploy_controller_name()
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - watch
- apiGroups:
  - cluster.x-k8s.io
  resources:
  - clusters
  verbs:
  - get
  - list
  - watch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: #@ post_deploy_controller_name()
subjects:
  - kind: ServiceAccount
    name: #@ post_deploy_controller_sa_name()
    namespace: #@ pinniped_supervisor_namespace()
roleRef:
  kind: ClusterRole
  name: #@ post_deploy_controller_name()
  apiGroup: rbac.authorization.k8s.io
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: #@ post_deploy_controller_name()
  namespace: #@ pinniped_supervisor_namespace()
spec:
  selector:
    matchLabels:
      app: #@ post_deploy_controller_name()
  template:
    metadata:
      labels:
        app: #@ post_deploy_controller_name()
    #! TODO: check out the spec of other packages, such as addons-manager-v1 for resource limits, etc.
    #! we probably want to flesh this out.
    spec:
      serviceAccountName: #@ post_deploy_controller_sa_name()
      containers:
      - image: projects.registry.vmware.com/tce/tanzu_core/addons/tkg-pinniped-post-deploy:v1.3.1
        name: #@ post_deploy_controller_name()
        command: ["/tkg-pinniped-post-deploy-controller"]
#@ end
